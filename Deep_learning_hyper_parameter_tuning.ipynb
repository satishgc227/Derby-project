{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satishgc227/Derby-project/blob/main/Deep_learning_hyper_parameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTFysGRca-x5",
        "outputId": "3e7a1243-65d2-49d4-e0cc-b7fbe8632855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.3.0\n"
          ]
        }
      ],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "\n",
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wck7ge22bc8_"
      },
      "outputs": [],
      "source": [
        "# Make scorer accuracy\n",
        "score_acc = make_scorer(accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guQ9yYh4bdoA",
        "outputId": "7ab546bd-d67a-48df-c652-8a2c85c0d861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array(['ALW', 'AOC', 'CLM', 'SST'], dtype=object), array(['D', 'I', 'M', 'O', 'T'], dtype=object), array(['FM ', 'FT ', 'GD ', 'MY ', 'SY '], dtype=object), array(['AQU', 'BEL', 'SAR'], dtype=object)]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting movecolumn\n",
            "  Downloading movecolumn-0.0.7.tar.gz (6.4 kB)\n",
            "Building wheels for collected packages: movecolumn\n",
            "  Building wheel for movecolumn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for movecolumn: filename=movecolumn-0.0.7-py3-none-any.whl size=10440 sha256=1462b9f82aa9ea82f4cc04c455da1a75512d52154ef6f829c379f770f16d923c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/ad/b7/671cd4a6e1464bb816aea3bacdcc933acf25e3d47946a7edcf\n",
            "Successfully built movecolumn\n",
            "Installing collected packages: movecolumn\n",
            "Successfully installed movecolumn-0.0.7\n"
          ]
        }
      ],
      "source": [
        "# Load in the data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "df = pd.read_csv('/content/edited complete.csv',encoding='latin',nrows=10000)\n",
        "\n",
        "df['race_type\\xa0'].unique()\n",
        "df['course_type'].unique()\n",
        "df['track_condition\\xa0'].unique()\n",
        "df['track_id'].unique()\n",
        "\n",
        "s=df[['race_type\\xa0','course_type','track_condition\\xa0','track_id']]\n",
        "\n",
        "ohe=OneHotEncoder()\n",
        "feature_array=ohe.fit_transform(df[['race_type\\xa0','course_type','track_condition\\xa0','track_id']]).toarray()\n",
        "\n",
        "feature_labels=ohe.categories_\n",
        "print(feature_labels)\n",
        "\n",
        "np.hstack(feature_labels)\n",
        "\n",
        "feature_labels=np.hstack(feature_labels)\n",
        "f=pd.DataFrame(feature_array,columns=feature_labels)\n",
        "pd.concat([df,f],axis=1)\n",
        "\n",
        "df.drop(['race_date','track_id','course_type','track_condition\\xa0','race_type\\xa0','jockey\\xa0','program_number\\xa0','latitude\\xa0','longitude\\xa0'],axis=1,inplace=True)\n",
        "df=pd.concat([df,f],axis=1)\n",
        "\n",
        "df.isnull().any()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Removing the null values\"\"\"\n",
        "\n",
        "df.replace([np.inf,-np.inf],np.nan ,inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().any()\n",
        "\n",
        "!pip install movecolumn\n",
        "import movecolumn as mc\n",
        "mc.MoveToLast(df,'position_at_finish\\xa0')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feu4KRNycXeN"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Create function\n",
        "def nn_cl_bo(neurons, activation, optimizer, learning_rate,  batch_size, epochs ):\n",
        "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
        "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
        "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
        "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
        "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "                   'elu', 'exponential', LeakyReLU,'relu']\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    def nn_cl_fun():\n",
        "        opt = Adam(lr = learning_rate)\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=10, activation=activation))\n",
        "        nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1, activation='sigmoid'))\n",
        "        nn.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size,\n",
        "                         verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdA3QOXEl019",
        "outputId": "054d3561-d7f7-4ec3-917d-699590649c81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "race_number            False\n",
              "trakus_index           False\n",
              "distance_id            False\n",
              "run_up_distance        False\n",
              "purse                  False\n",
              "post_time              False\n",
              "weight_carried         False\n",
              "odds                   False\n",
              "ALW                    False\n",
              "AOC                    False\n",
              "CLM                    False\n",
              "SST                    False\n",
              "D                      False\n",
              "I                      False\n",
              "M                      False\n",
              "O                      False\n",
              "T                      False\n",
              "FM                     False\n",
              "FT                     False\n",
              "GD                     False\n",
              "MY                     False\n",
              "SY                     False\n",
              "AQU                    False\n",
              "BEL                    False\n",
              "SAR                    False\n",
              "position_at_finish     False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.replace([np.inf,-np.inf],np.nan ,inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "eK409LBrdJH6",
        "outputId": "a49fb6e9-d9d1-495c-e51a-56d28b404bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  epochs   | learni... |  neurons  | optimizer |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.51     \u001b[0m | \u001b[0m335.3    \u001b[0m | \u001b[0m54.88    \u001b[0m | \u001b[0m0.7716   \u001b[0m | \u001b[0m36.58    \u001b[0m | \u001b[0m1.044    \u001b[0m |\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.2023   \u001b[0m | \u001b[0m536.2    \u001b[0m | \u001b[0m39.09    \u001b[0m | \u001b[0m0.3443   \u001b[0m | \u001b[0m99.16    \u001b[0m | \u001b[0m1.664    \u001b[0m |\n",
            "| \u001b[0m3        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.7307   \u001b[0m | \u001b[0m735.7    \u001b[0m | \u001b[0m69.7     \u001b[0m | \u001b[0m0.2815   \u001b[0m | \u001b[0m51.96    \u001b[0m | \u001b[0m0.8286   \u001b[0m |\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.6656   \u001b[0m | \u001b[0m920.6    \u001b[0m | \u001b[0m83.52    \u001b[0m | \u001b[0m0.8422   \u001b[0m | \u001b[0m83.37    \u001b[0m | \u001b[0m6.937    \u001b[0m |\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.195    \u001b[0m | \u001b[0m851.0    \u001b[0m | \u001b[0m53.71    \u001b[0m | \u001b[0m0.03717  \u001b[0m | \u001b[0m50.87    \u001b[0m | \u001b[0m0.7373   \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m7.355    \u001b[0m | \u001b[0m758.2    \u001b[0m | \u001b[0m65.22    \u001b[0m | \u001b[0m0.2815   \u001b[0m | \u001b[0m99.86    \u001b[0m | \u001b[0m0.9663   \u001b[0m |\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.539    \u001b[0m | \u001b[0m588.0    \u001b[0m | \u001b[0m52.4     \u001b[0m | \u001b[0m0.7306   \u001b[0m | \u001b[0m39.05    \u001b[0m | \u001b[0m2.804    \u001b[0m |\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.871    \u001b[0m | \u001b[0m957.8    \u001b[0m | \u001b[0m93.5     \u001b[0m | \u001b[0m0.8157   \u001b[0m | \u001b[0m13.07    \u001b[0m | \u001b[0m6.604    \u001b[0m |\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m8.554    \u001b[0m | \u001b[0m845.3    \u001b[0m | \u001b[0m58.5     \u001b[0m | \u001b[0m0.9671   \u001b[0m | \u001b[0m47.53    \u001b[0m | \u001b[0m2.232    \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.148    \u001b[0m | \u001b[0m230.5    \u001b[0m | \u001b[0m24.25    \u001b[0m | \u001b[0m0.1367   \u001b[0m | \u001b[0m13.0     \u001b[0m | \u001b[0m1.585    \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.895    \u001b[0m | \u001b[0m342.9    \u001b[0m | \u001b[0m34.35    \u001b[0m | \u001b[0m0.1581   \u001b[0m | \u001b[0m71.47    \u001b[0m | \u001b[0m3.283    \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m6.914    \u001b[0m | \u001b[0m735.1    \u001b[0m | \u001b[0m55.3     \u001b[0m | \u001b[0m0.5993   \u001b[0m | \u001b[0m51.55    \u001b[0m | \u001b[0m6.743    \u001b[0m |\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.33     \u001b[0m | \u001b[0m925.5    \u001b[0m | \u001b[0m59.83    \u001b[0m | \u001b[0m0.5966   \u001b[0m | \u001b[0m71.62    \u001b[0m | \u001b[0m1.242    \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m7.782    \u001b[0m | \u001b[0m585.7    \u001b[0m | \u001b[0m25.55    \u001b[0m | \u001b[0m0.3711   \u001b[0m | \u001b[0m42.54    \u001b[0m | \u001b[0m3.304    \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.615    \u001b[0m | \u001b[0m340.2    \u001b[0m | \u001b[0m95.93    \u001b[0m | \u001b[0m0.6591   \u001b[0m | \u001b[0m22.15    \u001b[0m | \u001b[0m6.495    \u001b[0m |\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m7.576    \u001b[0m | \u001b[0m242.2    \u001b[0m | \u001b[0m36.29    \u001b[0m | \u001b[0m0.8738   \u001b[0m | \u001b[0m70.65    \u001b[0m | \u001b[0m2.081    \u001b[0m |\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m6.61     \u001b[0m | \u001b[0m694.7    \u001b[0m | \u001b[0m36.84    \u001b[0m | \u001b[0m0.804    \u001b[0m | \u001b[0m15.32    \u001b[0m | \u001b[0m2.158    \u001b[0m |\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.866    \u001b[0m | \u001b[0m977.8    \u001b[0m | \u001b[0m92.75    \u001b[0m | \u001b[0m0.6797   \u001b[0m | \u001b[0m20.37    \u001b[0m | \u001b[0m6.706    \u001b[0m |\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.8254   \u001b[0m | \u001b[0m703.8    \u001b[0m | \u001b[0m92.23    \u001b[0m | \u001b[0m0.3464   \u001b[0m | \u001b[0m68.75    \u001b[0m | \u001b[0m6.476    \u001b[0m |\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m3.366    \u001b[0m | \u001b[0m817.1    \u001b[0m | \u001b[0m91.69    \u001b[0m | \u001b[0m0.624    \u001b[0m | \u001b[0m23.6     \u001b[0m | \u001b[0m2.624    \u001b[0m |\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.723    \u001b[0m | \u001b[0m567.3    \u001b[0m | \u001b[0m62.58    \u001b[0m | \u001b[0m0.3588   \u001b[0m | \u001b[0m69.39    \u001b[0m | \u001b[0m3.336    \u001b[0m |\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.091    \u001b[0m | \u001b[0m299.8    \u001b[0m | \u001b[0m53.0     \u001b[0m | \u001b[0m0.2804   \u001b[0m | \u001b[0m41.21    \u001b[0m | \u001b[0m6.821    \u001b[0m |\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.94     \u001b[0m | \u001b[0m746.3    \u001b[0m | \u001b[0m22.54    \u001b[0m | \u001b[0m0.837    \u001b[0m | \u001b[0m73.15    \u001b[0m | \u001b[0m6.762    \u001b[0m |\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.326    \u001b[0m | \u001b[0m373.9    \u001b[0m | \u001b[0m77.54    \u001b[0m | \u001b[0m0.04056  \u001b[0m | \u001b[0m47.68    \u001b[0m | \u001b[0m1.969    \u001b[0m |\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.9562   \u001b[0m | \u001b[0m541.1    \u001b[0m | \u001b[0m87.25    \u001b[0m | \u001b[0m0.1193   \u001b[0m | \u001b[0m98.8     \u001b[0m | \u001b[0m1.633    \u001b[0m |\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEmpty\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-34fe8e9775e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Run Bayesian Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnn_bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_cl_bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnn_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_constrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 self.constraint.fit(self._space.params,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         y = check_array(\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "source": [
        "# Set paramaters\n",
        "params_nn ={\n",
        "    'neurons': (10, 100),\n",
        "    'activation':(0, 9),\n",
        "    'optimizer':(0,7),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(200, 1000),\n",
        "    'epochs':(20, 100)\n",
        "}\n",
        "# Run Bayesian Optimization\n",
        "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\n",
        "nn_bo.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydWRri2vdKg2",
        "outputId": "b71fbb40-3fa5-4adc-9638-ea29a4380527"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'elu',\n",
              " 'batch_size': 335.25580347650913,\n",
              " 'dropout': 0.4360590193711702,\n",
              " 'dropout_rate': 0.23077874175693686,\n",
              " 'epochs': 43.6260243522301,\n",
              " 'layers1': 1.2983259142789796,\n",
              " 'layers2': 1.0449566490883235,\n",
              " 'learning_rate': 0.42602224734191213,\n",
              " 'neurons': 31.481392712180146,\n",
              " 'normalization': 0.33765619188879237,\n",
              " 'optimizer': 6.934987252416151}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Here are the best hyperparameters.\n",
        "\n",
        "params_nn_ = nn_bo.max['params']\n",
        "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "               'elu', 'exponential', LeakyReLU,'relu']\n",
        "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
        "params_nn_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0tdg1_qdTcE"
      },
      "outputs": [],
      "source": [
        "#The following code creates a function for tuning the Neural Network hyperparameters and layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "wq9zrapbdaKe",
        "outputId": "52ed535e-399f-4280-cc7d-9c535ef9b7b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.51     \u001b[0m | \u001b[0m335.3    \u001b[0m | \u001b[0m0.4361   \u001b[0m | \u001b[0m0.2308   \u001b[0m | \u001b[0m43.63    \u001b[0m | \u001b[0m1.298    \u001b[0m | \u001b[0m1.045    \u001b[0m | \u001b[0m0.426    \u001b[0m | \u001b[0m31.48    \u001b[0m | \u001b[0m0.3377   \u001b[0m | \u001b[0m6.935    \u001b[0m |\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.14     \u001b[0m | \u001b[0m265.0    \u001b[0m | \u001b[0m0.6696   \u001b[0m | \u001b[0m0.1864   \u001b[0m | \u001b[0m41.94    \u001b[0m | \u001b[0m1.932    \u001b[0m | \u001b[0m1.237    \u001b[0m | \u001b[0m0.08322  \u001b[0m | \u001b[0m91.07    \u001b[0m | \u001b[0m0.794    \u001b[0m | \u001b[0m5.884    \u001b[0m |\n",
            "| \u001b[0m3        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m7.337    \u001b[0m | \u001b[0m992.8    \u001b[0m | \u001b[0m0.5773   \u001b[0m | \u001b[0m0.2441   \u001b[0m | \u001b[0m53.71    \u001b[0m | \u001b[0m1.055    \u001b[0m | \u001b[0m1.908    \u001b[0m | \u001b[0m0.1143   \u001b[0m | \u001b[0m83.55    \u001b[0m | \u001b[0m0.6977   \u001b[0m | \u001b[0m3.957    \u001b[0m |\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.468    \u001b[0m | \u001b[0m998.8    \u001b[0m | \u001b[0m0.138    \u001b[0m | \u001b[0m0.1846   \u001b[0m | \u001b[0m58.8     \u001b[0m | \u001b[0m1.81     \u001b[0m | \u001b[0m2.456    \u001b[0m | \u001b[0m0.3296   \u001b[0m | \u001b[0m46.05    \u001b[0m | \u001b[0m0.319    \u001b[0m | \u001b[0m6.631    \u001b[0m |\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m8.268    \u001b[0m | \u001b[0m851.1    \u001b[0m | \u001b[0m0.03408  \u001b[0m | \u001b[0m0.283    \u001b[0m | \u001b[0m96.04    \u001b[0m | \u001b[0m2.613    \u001b[0m | \u001b[0m1.963    \u001b[0m | \u001b[0m0.9671   \u001b[0m | \u001b[0m47.53    \u001b[0m | \u001b[0m0.3188   \u001b[0m | \u001b[0m0.1151   \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.3436   \u001b[0m | \u001b[0m242.5    \u001b[0m | \u001b[0m0.128    \u001b[0m | \u001b[0m0.01001  \u001b[0m | \u001b[0m38.11    \u001b[0m | \u001b[0m2.088    \u001b[0m | \u001b[0m1.357    \u001b[0m | \u001b[0m0.1876   \u001b[0m | \u001b[0m23.47    \u001b[0m | \u001b[0m0.683    \u001b[0m | \u001b[0m3.283    \u001b[0m |\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m6.914    \u001b[0m | \u001b[0m735.1    \u001b[0m | \u001b[0m0.4413   \u001b[0m | \u001b[0m0.1786   \u001b[0m | \u001b[0m56.93    \u001b[0m | \u001b[0m2.927    \u001b[0m | \u001b[0m1.296    \u001b[0m | \u001b[0m0.9077   \u001b[0m | \u001b[0m54.81    \u001b[0m | \u001b[0m0.5925   \u001b[0m | \u001b[0m4.793    \u001b[0m |\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.597    \u001b[0m | \u001b[0m891.7    \u001b[0m | \u001b[0m0.4821   \u001b[0m | \u001b[0m0.0208   \u001b[0m | \u001b[0m49.18    \u001b[0m | \u001b[0m1.723    \u001b[0m | \u001b[0m1.944    \u001b[0m | \u001b[0m0.1877   \u001b[0m | \u001b[0m25.78    \u001b[0m | \u001b[0m0.9491   \u001b[0m | \u001b[0m4.59     \u001b[0m |\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.215    \u001b[0m | \u001b[0m942.2    \u001b[0m | \u001b[0m0.8418   \u001b[0m | \u001b[0m0.01583  \u001b[0m | \u001b[0m36.29    \u001b[0m | \u001b[0m2.745    \u001b[0m | \u001b[0m2.348    \u001b[0m | \u001b[0m0.3043   \u001b[0m | \u001b[0m76.1     \u001b[0m | \u001b[0m0.6183   \u001b[0m | \u001b[0m1.473    \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m7.219    \u001b[0m | \u001b[0m247.3    \u001b[0m | \u001b[0m0.3082   \u001b[0m | \u001b[0m0.06221  \u001b[0m | \u001b[0m97.78    \u001b[0m | \u001b[0m2.819    \u001b[0m | \u001b[0m2.353    \u001b[0m | \u001b[0m0.124    \u001b[0m | \u001b[0m96.22    \u001b[0m | \u001b[0m0.09171  \u001b[0m | \u001b[0m4.409    \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m8.126    \u001b[0m | \u001b[0m471.8    \u001b[0m | \u001b[0m0.6528   \u001b[0m | \u001b[0m0.2775   \u001b[0m | \u001b[0m49.92    \u001b[0m | \u001b[0m2.543    \u001b[0m | \u001b[0m2.792    \u001b[0m | \u001b[0m0.624    \u001b[0m | \u001b[0m23.6     \u001b[0m | \u001b[0m0.3749   \u001b[0m | \u001b[0m4.451    \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.132    \u001b[0m | \u001b[0m625.8    \u001b[0m | \u001b[0m0.3523   \u001b[0m | \u001b[0m0.198    \u001b[0m | \u001b[0m58.12    \u001b[0m | \u001b[0m1.909    \u001b[0m | \u001b[0m1.25     \u001b[0m | \u001b[0m0.4183   \u001b[0m | \u001b[0m34.58    \u001b[0m | \u001b[0m0.3467   \u001b[0m | \u001b[0m6.821    \u001b[0m |\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.94     \u001b[0m | \u001b[0m746.3    \u001b[0m | \u001b[0m0.03181  \u001b[0m | \u001b[0m0.2506   \u001b[0m | \u001b[0m76.13    \u001b[0m | \u001b[0m2.932    \u001b[0m | \u001b[0m2.184    \u001b[0m | \u001b[0m0.2252   \u001b[0m | \u001b[0m74.73    \u001b[0m | \u001b[0m0.03087  \u001b[0m | \u001b[0m2.931    \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.531    \u001b[0m | \u001b[0m285.0    \u001b[0m | \u001b[0m0.4263   \u001b[0m | \u001b[0m0.2522   \u001b[0m | \u001b[0m28.83    \u001b[0m | \u001b[0m2.973    \u001b[0m | \u001b[0m1.467    \u001b[0m | \u001b[0m0.7242   \u001b[0m | \u001b[0m69.48    \u001b[0m | \u001b[0m0.07776  \u001b[0m | \u001b[0m4.881    \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.388    \u001b[0m | \u001b[0m921.5    \u001b[0m | \u001b[0m0.8183   \u001b[0m | \u001b[0m0.1198   \u001b[0m | \u001b[0m85.62    \u001b[0m | \u001b[0m1.396    \u001b[0m | \u001b[0m2.045    \u001b[0m | \u001b[0m0.4184   \u001b[0m | \u001b[0m93.33    \u001b[0m | \u001b[0m0.8254   \u001b[0m | \u001b[0m3.507    \u001b[0m |\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.051    \u001b[0m | \u001b[0m209.3    \u001b[0m | \u001b[0m0.9132   \u001b[0m | \u001b[0m0.1537   \u001b[0m | \u001b[0m87.45    \u001b[0m | \u001b[0m1.19     \u001b[0m | \u001b[0m2.607    \u001b[0m | \u001b[0m0.07161  \u001b[0m | \u001b[0m67.19    \u001b[0m | \u001b[0m0.9688   \u001b[0m | \u001b[0m2.782    \u001b[0m |\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.936    \u001b[0m | \u001b[0m371.9    \u001b[0m | \u001b[0m0.8899   \u001b[0m | \u001b[0m0.296    \u001b[0m | \u001b[0m79.09    \u001b[0m | \u001b[0m2.283    \u001b[0m | \u001b[0m1.504    \u001b[0m | \u001b[0m0.4811   \u001b[0m | \u001b[0m34.13    \u001b[0m | \u001b[0m0.8683   \u001b[0m | \u001b[0m1.868    \u001b[0m |\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m8.757    \u001b[0m | \u001b[0m370.8    \u001b[0m | \u001b[0m0.2978   \u001b[0m | \u001b[0m0.221    \u001b[0m | \u001b[0m21.03    \u001b[0m | \u001b[0m1.06     \u001b[0m | \u001b[0m2.468    \u001b[0m | \u001b[0m0.5033   \u001b[0m | \u001b[0m29.63    \u001b[0m | \u001b[0m0.00893  \u001b[0m | \u001b[0m5.955    \u001b[0m |\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.828    \u001b[0m | \u001b[0m778.8    \u001b[0m | \u001b[0m0.6616   \u001b[0m | \u001b[0m0.2516   \u001b[0m | \u001b[0m51.06    \u001b[0m | \u001b[0m1.852    \u001b[0m | \u001b[0m2.656    \u001b[0m | \u001b[0m0.4743   \u001b[0m | \u001b[0m83.8     \u001b[0m | \u001b[0m0.01418  \u001b[0m | \u001b[0m2.777    \u001b[0m |\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.155    \u001b[0m | \u001b[0m294.5    \u001b[0m | \u001b[0m0.206    \u001b[0m | \u001b[0m0.2243   \u001b[0m | \u001b[0m94.41    \u001b[0m | \u001b[0m1.761    \u001b[0m | \u001b[0m1.921    \u001b[0m | \u001b[0m0.8746   \u001b[0m | \u001b[0m83.31    \u001b[0m | \u001b[0m0.02497  \u001b[0m | \u001b[0m6.111    \u001b[0m |\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.441    \u001b[0m | \u001b[0m613.2    \u001b[0m | \u001b[0m0.5893   \u001b[0m | \u001b[0m0.2399   \u001b[0m | \u001b[0m33.86    \u001b[0m | \u001b[0m1.374    \u001b[0m | \u001b[0m1.516    \u001b[0m | \u001b[0m0.06056  \u001b[0m | \u001b[0m59.74    \u001b[0m | \u001b[0m0.3518   \u001b[0m | \u001b[0m6.419    \u001b[0m |\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.289    \u001b[0m | \u001b[0m283.6    \u001b[0m | \u001b[0m0.1525   \u001b[0m | \u001b[0m0.08206  \u001b[0m | \u001b[0m82.52    \u001b[0m | \u001b[0m1.786    \u001b[0m | \u001b[0m2.598    \u001b[0m | \u001b[0m0.4387   \u001b[0m | \u001b[0m17.34    \u001b[0m | \u001b[0m0.01064  \u001b[0m | \u001b[0m3.016    \u001b[0m |\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.966    \u001b[0m | \u001b[0m612.2    \u001b[0m | \u001b[0m0.5801   \u001b[0m | \u001b[0m0.1479   \u001b[0m | \u001b[0m79.24    \u001b[0m | \u001b[0m2.579    \u001b[0m | \u001b[0m2.562    \u001b[0m | \u001b[0m0.1363   \u001b[0m | \u001b[0m94.61    \u001b[0m | \u001b[0m0.8777   \u001b[0m | \u001b[0m4.897    \u001b[0m |\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m8.432    \u001b[0m | \u001b[0m739.0    \u001b[0m | \u001b[0m0.5944   \u001b[0m | \u001b[0m0.1035   \u001b[0m | \u001b[0m26.69    \u001b[0m | \u001b[0m2.159    \u001b[0m | \u001b[0m1.035    \u001b[0m | \u001b[0m0.5569   \u001b[0m | \u001b[0m66.93    \u001b[0m | \u001b[0m0.6784   \u001b[0m | \u001b[0m1.194    \u001b[0m |\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.194    \u001b[0m | \u001b[0m364.8    \u001b[0m | \u001b[0m0.2515   \u001b[0m | \u001b[0m0.2908   \u001b[0m | \u001b[0m91.73    \u001b[0m | \u001b[0m1.246    \u001b[0m | \u001b[0m2.762    \u001b[0m | \u001b[0m0.9485   \u001b[0m | \u001b[0m51.39    \u001b[0m | \u001b[0m0.413    \u001b[0m | \u001b[0m4.04     \u001b[0m |\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEmpty\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fc88b9537bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Run Bayesian Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mnn_bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_cl_bo2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_nn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mnn_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_constrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 self.constraint.fit(self._space.params,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         y = check_array(\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "source": [
        "# Create function\n",
        "def nn_cl_bo2(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
        "              layers1, layers2, normalization, dropout, dropout_rate):\n",
        "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
        "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
        "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
        "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
        "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "                   'elu', 'exponential', LeakyReLU,'relu']\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    layers1 = round(layers1)\n",
        "    layers2 = round(layers2)\n",
        "    def nn_cl_fun():\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=10, activation=activation))\n",
        "        if normalization > 0.5:\n",
        "            nn.add(BatchNormalization())\n",
        "        for i in range(layers1):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        if dropout > 0.5:\n",
        "            nn.add(Dropout(dropout_rate, seed=123))\n",
        "        for i in range(layers2):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1, activation='sigmoid'))\n",
        "        nn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score\n",
        "\n",
        "#The following code searches for the optimum hyperparameters and layers for the Neural Network model.\n",
        "\n",
        "params_nn2 ={\n",
        "    'neurons': (10, 100),\n",
        "    'activation':(0, 9),\n",
        "    'optimizer':(0,7),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(200, 1000),\n",
        "    'epochs':(20, 100),\n",
        "    'layers1':(1,3),\n",
        "    'layers2':(1,3),\n",
        "    'normalization':(0,1),\n",
        "    'dropout':(0,1),\n",
        "    'dropout_rate':(0,0.3)\n",
        "}\n",
        "# Run Bayesian Optimization\n",
        "nn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\n",
        "nn_bo.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDpGNHcDdiJi"
      },
      "outputs": [],
      "source": [
        "#Here are the tuned hyperparameters and layers.\n",
        "params_nn_ = nn_bo.max['params']\n",
        "learning_rate = params_nn_['learning_rate']\n",
        "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "               'elu', 'exponential', LeakyReLU,'relu']\n",
        "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
        "params_nn_['batch_size'] = round(params_nn_['batch_size'])\n",
        "params_nn_['epochs'] = round(params_nn_['epochs'])\n",
        "params_nn_['layers1'] = round(params_nn_['layers1'])\n",
        "params_nn_['layers2'] = round(params_nn_['layers2'])\n",
        "params_nn_['neurons'] = round(params_nn_['neurons'])\n",
        "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
        "optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
        "             'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
        "             'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
        "             'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
        "params_nn_['optimizer'] = optimizerD[optimizerL[round(params_nn_['optimizer'])]]\n",
        "params_nn_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL0AkZiji_nV"
      },
      "outputs": [],
      "source": [
        "#Fitting Neural Network\n",
        "def nn_cl_fun():\n",
        "  nn = Sequential()\n",
        "  nn.add(Dense(params_nn_['neurons'], input_dim=25, activation=params_nn_['activation']))\n",
        "  if params_nn_['normalization'] > 0.5:\n",
        "    nn.add(BatchNormalization())\n",
        "  for i in range(params_nn_['layers1']):\n",
        "    nn.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\n",
        "  if params_nn_['dropout'] > 0.5:\n",
        "    nn.add(Dropout(params_nn_['dropout_rate'], seed=123))\n",
        "  for i in range(params_nn_['layers2']):\n",
        "    nn.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\n",
        "  nn.add(Dense(1, activation='sigmoid'))\n",
        "  nn.compile(loss='binary_crossentropy', optimizer=params_nn_['optimizer'], metrics=['accuracy'])\n",
        "  return nn\n",
        "es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
        "nn = KerasClassifier(build_fn=nn_cl_fun, epochs=params_nn_['epochs'], batch_size=params_nn_['batch_size'],\n",
        "                         verbose=0)\n",
        "nn.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WNLrAxRlGSJ"
      },
      "outputs": [],
      "source": [
        "print('X_train dimension= ', X_train.shape)\n",
        "print('X_test dimension= ', X_test.shape)\n",
        "print('y_train dimension= ', y_train.shape)\n",
        "print('y_test dimension= ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXBTNcNHl8SB"
      },
      "outputs": [],
      "source": [
        "# import tensorflow and fix the random seed for better reproducibility\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "# import the necessary packages\n",
        "\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfaiylXjsWli"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def get_mlp_model(hiddenLayerOne=784, hiddenLayerTwo=256,\n",
        "\tdropout=0.2, learnRate=0.01):\n",
        "\t# initialize a sequential model and add layer to flatten the\n",
        "\t# input data\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Flatten())\n",
        "  \t# add two stacks of FC => RELU => DROPOUT\n",
        "\tmodel.add(Dense(hiddenLayerOne, activation=\"relu\",\n",
        "\t\tinput_shape=(784,)))\n",
        "\tmodel.add(Dropout(dropout))\n",
        "\tmodel.add(Dense(hiddenLayerTwo, activation=\"relu\"))\n",
        "\tmodel.add(Dropout(dropout))\n",
        "\t# add a softmax layer on top\n",
        "\tmodel.add(Dense(10, activation=\"softmax\"))\n",
        "\t# compile the model\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=Adam(learning_rate=learnRate),\n",
        "\t\tloss=\"sparse_categorical_crossentropy\",\n",
        "\t\tmetrics=[\"accuracy\"])\n",
        "\t# return compiled model\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O8fqOeoVsp4u",
        "outputId": "2b57d329-80d6-4d98-c585-a867858a0148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] initializing model...\n",
            "[INFO] training model...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-61b41e2ccdd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \tepochs=20)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# make predictions on the test set and evaluate it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] evaluating network...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-44-61b41e2ccdd5>\", line 9, in <module>\n      epochs=20)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 949, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1861, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5239, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 10 which is outside the valid range of [0, 10).  Label values: 2 2 3 8 2 2 10 1\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_132519]"
          ]
        }
      ],
      "source": [
        "# initialize our model with the default hyperparameter values\n",
        "print(\"[INFO] initializing model...\")\n",
        "model = get_mlp_model()\n",
        "# train the network (i.e., no hyperparameter tuning)\n",
        "print(\"[INFO] training model...\")\n",
        "H = model.fit(X_train,y_train,\n",
        "\tvalidation_data=(X_test,y_test),\n",
        "\tbatch_size=8,\n",
        "\tepochs=20)\n",
        "# make predictions on the test set and evaluate it\n",
        "print(\"[INFO] evaluating network...\")\n",
        "accuracy = model.evaluate(X_test,y_test)[1]\n",
        "print(\"accuracy: {:.2f}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuuCi_AAn1I2",
        "outputId": "ebcfec09-d7b3-4aaf-8b03-9101339192b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] initializing model...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] initializing model...\")\n",
        "model = KerasClassifier(build_fn=get_mlp_model, verbose=0)\n",
        "# define a grid of the hyperparameter search space\n",
        "hiddenLayerOne = [256, 512, 784]\n",
        "hiddenLayerTwo = [128, 256, 512]\n",
        "learnRate = [1e-2, 1e-3, 1e-4]\n",
        "dropout = [0.3, 0.4, 0.5]\n",
        "batchSize = [4, 8, 16, 32]\n",
        "epochs = [10, 20, 30, 40]\n",
        "# create a dictionary from the hyperparameter grid\n",
        "grid = dict(\n",
        "\thiddenLayerOne=hiddenLayerOne,\n",
        "\tlearnRate=learnRate,\n",
        "\thiddenLayerTwo=hiddenLayerTwo,\n",
        "\tdropout=dropout,\n",
        "\tbatch_size=batchSize,\n",
        "\tepochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcXXiTrjoa6Q",
        "outputId": "3ad8f6b9-e07f-4e44-e048-586ebd0f163d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] performing random search...\n",
            "[INFO] best score is 0.28 using {'learnRate': 0.01, 'hiddenLayerTwo': 256, 'hiddenLayerOne': 784, 'epochs': 10, 'dropout': 0.3, 'batch_size': 16}\n"
          ]
        }
      ],
      "source": [
        "# initialize a random search with a 3-fold cross-validation and then\n",
        "# start the hyperparameter search process\n",
        "print(\"[INFO] performing random search...\")\n",
        "searcher = RandomizedSearchCV(estimator=model, n_jobs=-1, cv=3,\n",
        "\tparam_distributions=grid, scoring=\"accuracy\")\n",
        "searchResults = searcher.fit(X_train,y_train)\n",
        "# summarize grid search information\n",
        "bestScore = searchResults.best_score_\n",
        "bestParams = searchResults.best_params_\n",
        "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
        "\tbestParams))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ5QdlbaoeTu"
      },
      "outputs": [],
      "source": [
        "# extract the best model, make predictions on our data, and show a\n",
        "# classification report\n",
        "print(\"[INFO] evaluating the best model...\")\n",
        "bestModel = searchResults.best_estimator_\n",
        "accuracy = bestModel.score(X_train,y_train)\n",
        "print(\"accuracy: {:.2f}%\".format(accuracy * 100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPzehEWDq3q3FsHzRyIyeb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}