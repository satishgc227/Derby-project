{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3OygY8c7eElJ6/NOH6NdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satishgc227/Derby-project/blob/main/All_models_hyperparamter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8N0scSDgXo1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B3lAc4rLb3_D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model, decomposition\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import model_selection\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZDZ892VggvG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "df = pd.read_csv('/content/edited complete.csv',encoding='latin',nrows=10000)\n",
        "\n",
        "df['race_type\\xa0'].unique()\n",
        "df['course_type'].unique()\n",
        "df['track_condition\\xa0'].unique()\n",
        "df['track_id'].unique()\n",
        "\n",
        "s=df[['race_type\\xa0','course_type','track_condition\\xa0','track_id']]\n",
        "\n",
        "ohe=OneHotEncoder()\n",
        "feature_array=ohe.fit_transform(df[['race_type\\xa0','course_type','track_condition\\xa0','track_id']]).toarray()\n",
        "\n",
        "feature_labels=ohe.categories_\n",
        "print(feature_labels)\n",
        "\n",
        "np.hstack(feature_labels)\n",
        "\n",
        "feature_labels=np.hstack(feature_labels)\n",
        "f=pd.DataFrame(feature_array,columns=feature_labels)\n",
        "pd.concat([df,f],axis=1)\n",
        "\n",
        "df.drop(['race_date','track_id','course_type','track_condition\\xa0','race_type\\xa0','jockey\\xa0','program_number\\xa0','latitude\\xa0','longitude\\xa0'],axis=1,inplace=True)\n",
        "df=pd.concat([df,f],axis=1)\n",
        "\n",
        "df.isnull().any()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Removing the null values\"\"\"\n",
        "\n",
        "df.replace([np.inf,-np.inf],np.nan ,inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().any()\n",
        "\n",
        "!pip install movecolumn\n",
        "import movecolumn as mc\n",
        "mc.MoveToLast(df,'position_at_finish\\xa0')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybU5smfDcPlX",
        "outputId": "c9749202-c4d4-4f92-bd36-cbab7e5486c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array(['ALW', 'AOC', 'CLM', 'SST'], dtype=object), array(['D', 'I', 'M', 'O', 'T'], dtype=object), array(['FM ', 'FT ', 'GD ', 'MY ', 'SY '], dtype=object), array(['AQU', 'BEL', 'SAR'], dtype=object)]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting movecolumn\n",
            "  Downloading movecolumn-0.0.7.tar.gz (6.4 kB)\n",
            "Building wheels for collected packages: movecolumn\n",
            "  Building wheel for movecolumn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for movecolumn: filename=movecolumn-0.0.7-py3-none-any.whl size=10440 sha256=14a4fff6aaa621509cbdc7c200b0dc24228abebd1b2cf98f78bea33927ae5da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/ad/b7/671cd4a6e1464bb816aea3bacdcc933acf25e3d47946a7edcf\n",
            "Successfully built movecolumn\n",
            "Installing collected packages: movecolumn\n",
            "Successfully installed movecolumn-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "print('X_train dimension= ', X_train.shape)\n",
        "print('X_test dimension= ', X_test.shape)\n",
        "print('y_train dimension= ', y_train.shape)\n",
        "print('y_test dimension= ', y_test.shape)"
      ],
      "metadata": {
        "id": "7-UxKcFTOk0p",
        "outputId": "281903c7-c4e1-4e82-ecd5-a5936d98d1de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train dimension=  (8000, 25)\n",
            "X_test dimension=  (2000, 25)\n",
            "y_train dimension=  (8000,)\n",
            "y_test dimension=  (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression hyperparameter:"
      ],
      "metadata": {
        "id": "Xes9oLz7OlTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search logistic regression mode\n",
        "\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "fE9rRKmAgn_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029405d8-446d-42a2-86aa-fe0f131f2d3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 1.000000 using {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "1.000000 (0.000000) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "1.000000 (0.000000) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "1.000000 (0.000000) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "1.000000 (0.000000) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "1.000000 (0.000000) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "1.000000 (0.000000) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "1.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "1.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "1.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "1.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "1.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "1.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.976375 (0.005125) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.976375 (0.005125) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.927875 (0.003625) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB hyperparameter tuning"
      ],
      "metadata": {
        "id": "Ao3JeVLNOsKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model = GradientBoostingClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "subsample = [0.5, 0.7, 1.0]\n",
        "max_depth = [3, 7, 9]\n",
        "# define grid search\n",
        "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RESwwCrrMbO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "|# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "yMrqjo7ANQkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN Hyperparameter tuning:\n"
      ],
      "metadata": {
        "id": "71Ntd7gRO1Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# define models and parameters\n",
        "model = KNeighborsClassifier()\n",
        "n_neighbors = range(1, 21, 2)\n",
        "weights = ['uniform', 'distance']\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\n",
        "# define grid search\n",
        "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "EwKJzTKDO54Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM hyperparameter tuning:"
      ],
      "metadata": {
        "id": "wanh9ZDuPYBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# define model and parameters\n",
        "model = SVC()\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "C = [50, 10, 1.0, 0.1, 0.01]\n",
        "gamma = ['scale']\n",
        "# define grid search\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "fTlJK1Y-Pa8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest:"
      ],
      "metadata": {
        "id": "J2NjpIIpPpT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "max_features = ['sqrt', 'log2']\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "C86Nu5C6Pq9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_twMQVkQE83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging Classifier:"
      ],
      "metadata": {
        "id": "3XhBW_kYQJ8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# define models and parameters\n",
        "model = BaggingClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "IwTEeZaXQPVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rng7LeL2hIwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}